{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup as soup\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linksRetrieve(artistName, listName, url, targetString, nameList):\n",
    "    \"\"\"creates link list file\"\"\"\n",
    "    #retrieves html after permission granted\n",
    "    artistName=requests.get(url)\n",
    "    #convert request to coup object \n",
    "    pageHTML=soup(artistName.text, 'html.parser')\n",
    "    listName=[]\n",
    "    #retrieve every link from specific attribute and save into list \n",
    "    for link in pageHTML.find_all('a', attrs={'href':re.compile(targetString)}): \n",
    "        listName.append(link.get('href')) \n",
    "    listName=pd.DataFrame(listName)\n",
    "    listName.to_csv(nameList+'.csv', header=['links'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lyricRetrieve(linkFile, artistName):\n",
    "    \"\"\"retrieves lyrics from every link and adds it to a list\"\"\"\n",
    "    links=pd.read_csv(linkFile)\n",
    "    songDF=[] ##save all song lyrics into list \n",
    "    #while len(songDF) < len(linkFile):\n",
    "    for i in range(len(linkFile)):\n",
    "        url=links['links'].iloc[i] ##retrieve link from link list \n",
    "        songLink=requests.get(url) ##request permission to get info from site \n",
    "        songHTML=soup(songLink.text, 'html.parser') ##convert response to beautiful soup object\n",
    "        lines='' ##for lyrics of each song \n",
    "        result=songHTML.find_all('p', {'class':\"verse\"})\n",
    "        if not result:\n",
    "            print(result==True)\n",
    "            songDF.append('no lyrics')\n",
    "            continue\n",
    "        print(i)    \n",
    "        for line in songHTML.find_all('p', {'class':\"verse\"}): ##retrieve each tag chunk\n",
    "            line=str(line.text).replace('\\'', '%temp%').replace('\\n', ' ').replace('%temp%', '') ##convert to string and get rid of unwanted characters\n",
    "            lines=lines+line ##concatenate all lines together into 1 string \n",
    "            print('line added to list')\n",
    "        songDF.append(lines) ##append each string song into a single list\n",
    "        print('added lyrics to list') \n",
    "    print('left for loop')    \n",
    "    songDF=pd.DataFrame(songDF)\n",
    "    songDF.to_csv(artistName+'.csv', header=['songs'])##save as csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.metrolyrics.com/eminem-albums-list.html'\n",
    "linksRetrieve('eminem', 'eminemSongs', url, '-lyrics-eminem', 'eminemLinks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyricRetrieve('eminemLinks.csv', 'eminemLyrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=pd.read_csv('eminemLyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
